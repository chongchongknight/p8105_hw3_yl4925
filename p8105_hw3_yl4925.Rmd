---
title: "p8105_hw3_yl4925"
author: "Yiming Li"
date: "10/12/2021"
output: github_document
---

## Problem 1
```{r}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
```


```{r}
data("instacart")
instacart_row = nrow(instacart)
instacart_column = ncol(instacart)
```


```{r}
# this is structure for instacart 
str(instacart)
```

Instacart is an online grocery service that allows you to shop online from local stores.The size of this dataset is (`r instacart_row`, `r instacart_column`). We find that 4 out of 15 variables are character variable. They are eval_set, product_name, aisle and department. The rest 11 variables are integer variables. They are order_id, product_id, add_to_cart_order, reordered, user_id. order_number, order_dow, order_hour_of_day, days_since_prior_order, aisle_id and department_id. All id variables represent specific  accounts and items.

Reordered variables indicates whether this product has been ordered by this user in the past, with 1 is yes, 0 is no.

Order_number indicates the order sequence of users with n represents this is nth order for user.

Order_dow, order_hour_of_day and days_since_prior_order indicate time of making order and time interval from last order. For example, order_dow is 4 means order is made on Thursday. Order_hour_of_day is 10 means order is made on 10a.m. Days_since_prior_order is 30 means that last order is made 30 days before.

The rest variables indicate products' property.

```{r}
aisle = group_by(instacart, aisle) %>% 
  summarise(nobs = n()) %>% 
  arrange(-nobs)
aisle_row = nrow(aisle)
aisle_most = aisle$aisle[1]
```
There are totally `r aisle_row` aisles, and `r aisle_most` is aisle which the most items ordered from. 

Make a plot that shows the number of items vs aisle with more than 10000 items ordered. 
```{r}
aisle %>% 
  filter(nobs > 10000 ) %>%
  ggplot(aes(x = nobs, y = aisle)) + 
  labs(
    title = "Items in different aisle",
    x = "item count in each aisle",
    y = "aisle name"
  ) + geom_point() 
```

Three most popular items in "baking ingredients", "dog food care", and packaged vegetable fruits".
```{r}
instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  group_by(product_name) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  filter(1:n() <= 3)

instacart %>% 
  filter(aisle == "dog food care") %>% 
  group_by(product_name) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  filter(1:n() <= 3)

instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  group_by(product_name) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  filter(1:n() <= 3)

```

Mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week
```{r}
instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean
  ) 
```


## Problem 2
Load data
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

I do the data cleaning in this chunk and mainly focus on Overall Health topic. And also factor response variable from poor to excellent.
```{r}
brfss_clean = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = factor(response, 
                           levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), 
                           ordered = TRUE)) %>% 
  arrange(response)
```


No less than 7 observed in 2002 and 2010
```{r}
brfss_clean %>% 
  filter(year == 2002 | year == 2010) %>% 
  group_by(locationabbr, year) %>% 
  summarise(n_loca = n()) %>% 
  filter(n_loca >= 7) %>% 
  pivot_wider(
    names_from = year,
    values_from = n_loca
  )
```

Within excellent response, draw a plot of state mean data_value vs year
```{r}
excellent_resp = brfss_clean %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarise(state_mean = mean(data_value))
excellent_resp 

ggplot(excellent_resp, aes(x = year, y = state_mean)) + 
  labs(
    title = "State mean vs year"
  ) + 
  geom_line(aes(group = locationabbr))
  
```


Two-panel plot for different responses' data value distribution in 2006-NY and 2010-NY
```{r}
NY_2006 = brfss_clean %>% 
  filter(year == 2006) %>% 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density(alpha = .4, adjust = .5, color = "black") +
  theme(legend.position = "none")

NY_2010 = brfss_clean %>% 
  filter(year == 2010) %>% 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density(alpha = .4, adjust = .5, color = "black")

NY_2006 + NY_2010
```

## Problem 3
Load data(including dataset in local data directory)
```{r}
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(weekday_vs_weekend = case_when(
    day == "Monday"  ~ "Weekday",
    day == "Tuesday"  ~ "Weekday",
    day == "Wednesday"  ~ "Weekday",
    day == "Thursday"  ~ "Weekday",
    day == "Friday"  ~ "Weekday",
    day == "Sunday"  ~ "Weekend",
    day == "Saturday"  ~ "Weekend"
  )) %>% 
  select(week, day_id, day, weekday_vs_weekend, everything())


accel_df %>% 
  mutate(total_act = rowSums(accel_df[,c(-1, -2, -3, -4)])) %>% 
  select(week, day_id, day, weekday_vs_weekend, total_act) 
```
The size of this tidied dataset is (`r nrow(accel_df)`, `r ncol(accel_df)`). It includes a new character variable indicating whether it is weekday or weekend. Besides this variavble, this dataset has three time-reflected variables: week(week numeber), day_id(day number), day(Sunday to Saturday), and 1440 activity_k variables indicating the activity of $k_{th}$ minute during a day. And this dataframe contains records of 5 weeks(total 35 days).

Total activities over day
```{r}
Total_act_df = accel_df %>% 
  mutate(total_act = rowSums(accel_df[,c(-1, -2, -3, -4)])) %>% 
  select(week, day_id, day, weekday_vs_weekend, total_act) 

Total_act_df %>% 
  arrange(total_act)

Total_act_df %>% 
ggplot(aes(x = day_id, y = total_act, color = day)) + geom_point() + geom_line()
```
Actually we cannot easily see the trends from data table, so I make a plot. However, it is so messy to find exact trend even with plot. So there might be no apprent trends based on my current data and plot.


Draw a plot to show the 24-hour activity time courses for each day with color indicating day of the week. 
```{r}
accel_plot_df = accel_df %>% 
  select(-weekday_vs_weekend) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_number",
    values_to = "activity"
  ) %>% 
  separate(activity_number, into = c("prefix", "time_of_day"), sep = "_") %>% 
  select(-prefix) %>% 
  mutate(time_of_day = as.numeric(time_of_day)) 

accel_plot_df %>% 
  ggplot(aes(x = time_of_day, y = activity, color = day)) + 
  geom_point()

accel_plot_df %>% 
  mutate(time_of_day = day_id + time_of_day/1440) %>% 
  ggplot(aes(x = time_of_day, y = activity, color = day)) + 
  geom_point()
```
If we use scatter plot, we might find activity will increase firstly and decrease then. There is so many record in each day, so we can only find the shape for each day is just like a mountain. So I will try to sample some daily records on specific time of each day and see whether there are trends. 

```{r}
accel_plot_df %>% 
  filter(time_of_day %% 24 == 0) %>% 
  mutate(time_of_day = day_id + time_of_day/1440) %>% 
  ggplot(aes(x = time_of_day, y = activity, color = day)) + 
  geom_point()

```
It looks better, but still messy. I will try to omit actual time_of_day("day_id + time_of_day/1440" in my code), and combine all data from same day of week together(for example, all Monday's activity).

```{r}
accel_plot_df %>% 
  filter(time_of_day %% 24 == 0) %>% 
  ggplot(aes(x = time_of_day, y = activity, color = day)) + 
  geom_smooth(se = FALSE)
```
We can see there is an activity "peak" for each day, and "peak" time is close to noon.

I will try to use heatmap to show its trends.

```{r}
heatmap_df = accel_df %>% 
  mutate(day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", 
                                      "Thursday", "Friday", "Saturday"), ordered = TRUE)) %>% 
  arrange(day) %>% 
  mutate(modified_day_id = 1:35) %>% 
  select(-weekday_vs_weekend) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_number",
    values_to = "activity"
  ) %>% 
  separate(activity_number, into = c("prefix", "time_of_day"), sep = "_") %>% 
  select(-prefix) %>% 
  mutate(time_of_day = as.numeric(time_of_day))

heatmap_df %>% 
  ggplot(aes(x = time_of_day, y = modified_day_id, fill = day, alpha = activity)) +
  geom_tile() +
  labs(
    title = "heatmap for activity",
    x = "time of day",
    y = "day of week"
  ) +
  scale_x_continuous(
    breaks = c(0, 240, 480, 720, 960, 1200, 1440), 
    labels = c("0:00.", "4:00.","8:00", "12:00", "16:00", "20:00", "24:00"),
    limits = c(-1, 1441)) +
  scale_alpha(range = c(0.1, 2)) 
  
```

